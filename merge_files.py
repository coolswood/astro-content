#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è JSON —Ñ–∞–π–ª–æ–≤ –≤ –æ–¥–∏–Ω –æ–±—â–∏–π —Ñ–∞–π–ª.
–ü–æ–∑–≤–æ–ª—è–µ—Ç –æ–±—ä–µ–¥–∏–Ω—è—Ç—å —Ñ–∞–π–ª—ã –ø–æ –∑–∞–¥–∞–Ω–Ω—ã–º –≥—Ä—É–ø–ø–∞–º –¥–ª—è –≤—Å–µ—Ö —è–∑—ã–∫–æ–≤ –ø—Ä–æ–µ–∫—Ç–∞.

–ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:
python merge_files.py --category depression --files control death diagnostic --output control_death_diagnostic
python merge_files.py --category distortions --files achievements approval autonomy --output achievements_approval_autonomy
"""

import json
import os
import argparse
from pathlib import Path
from typing import List, Dict, Any

def get_available_languages(base_path: str) -> List[str]:
    """–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —è–∑—ã–∫–æ–≤ –≤ –ø—Ä–æ–µ–∫—Ç–µ"""
    languages = []
    base_dir = Path(base_path)

    for item in base_dir.iterdir():
        if item.is_dir() and len(item.name) == 2:  # —è–∑—ã–∫–æ–≤—ã–µ –∫–æ–¥—ã –æ–±—ã—á–Ω–æ 2 —Å–∏–º–≤–æ–ª–∞
            languages.append(item.name)
        elif item.name in ['pt_br']:  # –æ—Å–æ–±—ã–µ —Å–ª—É—á–∞–∏
            languages.append(item.name)

    return sorted(languages)

def load_json_file(file_path: str) -> Dict[str, Any]:
    """–ó–∞–≥—Ä—É–∑–∏—Ç—å JSON —Ñ–∞–π–ª"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError:
        print(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {file_path}")
        return {}
    except json.JSONDecodeError as e:
        print(f"–û—à–∏–±–∫–∞ JSON –≤ —Ñ–∞–π–ª–µ {file_path}: {e}")
        return {}

def merge_files_for_language(
    base_path: str,
    language: str,
    category: str,
    file_names: List[str]
) -> Dict[str, Any]:
    """–û–±—ä–µ–¥–∏–Ω–∏—Ç—å —Ñ–∞–π–ª—ã –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —è–∑—ã–∫–∞"""
    merged_content = {}

    for file_name in file_names:
        file_path = os.path.join(base_path, language, 'story', category, f"{file_name}.json")

        if os.path.exists(file_path):
            content = load_json_file(file_path)
            if content:
                merged_content[file_name] = content
                print(f"‚úÖ {language}/{category}/{file_name}.json - –¥–æ–±–∞–≤–ª–µ–Ω")
            else:
                print(f"‚ùå {language}/{category}/{file_name}.json - –æ—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏")
        else:
            print(f"‚ö†Ô∏è  {language}/{category}/{file_name}.json - —Ñ–∞–π–ª –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç")

    return merged_content

def save_merged_file(
    output_path: str,
    merged_content: Dict[str, Any],
    pretty: bool = True
) -> bool:
    """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π —Ñ–∞–π–ª"""
    try:
        with open(output_path, 'w', encoding='utf-8') as f:
            if pretty:
                json.dump(merged_content, f, ensure_ascii=False, indent=2)
            else:
                json.dump(merged_content, f, ensure_ascii=False)
        return True
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ñ–∞–π–ª–∞ {output_path}: {e}")
        return False

def validate_files_exist(
    base_path: str,
    languages: List[str],
    category: str,
    file_names: List[str]
) -> None:
    """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω–∞–ª–∏—á–∏–µ —Ñ–∞–π–ª–æ–≤ –∏ –ø–æ–∫–∞–∑–∞—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É"""
    print("\nüìä –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —Ñ–∞–π–ª–æ–≤:")
    print("-" * 50)

    total_files = 0
    existing_files = 0

    for language in languages:
        language_files = 0
        language_existing = 0

        for file_name in file_names:
            file_path = os.path.join(base_path, language, 'story', category, f"{file_name}.json")
            language_files += 1
            total_files += 1

            if os.path.exists(file_path):
                language_existing += 1
                existing_files += 1

        if language_existing == language_files:
            status = "‚úÖ"
        elif language_existing > 0:
            status = f"‚ö†Ô∏è  ({language_existing}/{language_files})"
        else:
            status = "‚ùå"

        print(f"{status} {language}: {language_existing}/{language_files} —Ñ–∞–π–ª–æ–≤")

    print(f"\n–ò—Ç–æ–≥–æ: {existing_files}/{total_files} —Ñ–∞–π–ª–æ–≤ –Ω–∞–π–¥–µ–Ω–æ")

def main():
    parser = argparse.ArgumentParser(
        description="–û–±—ä–µ–¥–∏–Ω–∏—Ç—å JSON —Ñ–∞–π–ª—ã –ø–æ –∑–∞–¥–∞–Ω–Ω—ã–º –≥—Ä—É–ø–ø–∞–º",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:
  # –û–±—ä–µ–¥–∏–Ω–∏—Ç—å —Ñ–∞–π–ª—ã –¥–µ–ø—Ä–µ—Å—Å–∏–∏ –¥–ª—è –≤—Å–µ—Ö —è–∑—ã–∫–æ–≤
  python merge_files.py --category depression --files control death diagnostic --output control_death_diagnostic

  # –û–±—ä–µ–¥–∏–Ω–∏—Ç—å —Ñ–∞–π–ª—ã –∏—Å–∫–∞–∂–µ–Ω–∏–π –¥–ª—è –≤—Å–µ—Ö —è–∑—ã–∫–æ–≤
  python merge_files.py --category distortions --files achievements approval autonomy --output achievements_approval_autonomy

  # –û–±—ä–µ–¥–∏–Ω–∏—Ç—å —Ç–æ–ª—å–∫–æ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —è–∑—ã–∫–æ–≤
  python merge_files.py --category depression --files control death diagnostic --output control_death_diagnostic --languages ru en de
        """
    )

    parser.add_argument(
        '--category',
        required=True,
        help='–ö–∞—Ç–µ–≥–æ—Ä–∏—è —Ñ–∞–π–ª–æ–≤ (–Ω–∞–ø—Ä–∏–º–µ—Ä: depression, distortions)'
    )

    parser.add_argument(
        '--files',
        nargs='+',
        required=True,
        help='–°–ø–∏—Å–æ–∫ –∏–º–µ–Ω —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è (–±–µ–∑ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è .json)'
    )

    parser.add_argument(
        '--output',
        required=True,
        help='–ò–º—è –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ (–±–µ–∑ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è .json)'
    )

    parser.add_argument(
        '--languages',
        nargs='+',
        help='–°–ø–∏—Å–æ–∫ —è–∑—ã–∫–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: –≤—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ —è–∑—ã–∫–∏)'
    )

    parser.add_argument(
        '--base-path',
        default='src/i18n',
        help='–ë–∞–∑–æ–≤—ã–π –ø—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å —è–∑—ã–∫–∞–º–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: src/i18n)'
    )

    parser.add_argument(
        '--dry-run',
        action='store_true',
        help='–¢–æ–ª—å–∫–æ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω–∞–ª–∏—á–∏–µ —Ñ–∞–π–ª–æ–≤, –Ω–µ —Å–æ–∑–¥–∞–≤–∞—Ç—å –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã'
    )

    parser.add_argument(
        '--compact',
        action='store_true',
        help='–°–æ–∑–¥–∞–≤–∞—Ç—å –∫–æ–º–ø–∞–∫—Ç–Ω—ã–π JSON –±–µ–∑ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è'
    )

    args = parser.parse_args()

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –±–∞–∑–æ–≤–æ–≥–æ –ø—É—Ç–∏
    if not os.path.exists(args.base_path):
        print(f"‚ùå –ë–∞–∑–æ–≤—ã–π –ø—É—Ç—å –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {args.base_path}")
        return 1

    # –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ —è–∑—ã–∫–æ–≤
    if args.languages:
        languages = args.languages
    else:
        languages = get_available_languages(args.base_path)

    print(f"üåç –Ø–∑—ã–∫–∏ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {', '.join(languages)}")
    print(f"üìÅ –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {args.category}")
    print(f"üìÑ –§–∞–π–ª—ã –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è: {', '.join(args.files)}")
    print(f"üíæ –í—ã—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª: {args.output}.json")

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —Ñ–∞–π–ª–æ–≤
    validate_files_exist(args.base_path, languages, args.category, args.files)

    if args.dry_run:
        print("\nüîç –†–µ–∂–∏–º –ø—Ä–æ–≤–µ—Ä–∫–∏ - —Ñ–∞–π–ª—ã –Ω–µ —Å–æ–∑–¥–∞–Ω—ã")
        return 0

    print(f"\nüöÄ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ñ–∞–π–ª–æ–≤...")

    success_count = 0
    total_count = len(languages)

    for language in languages:
        print(f"\nüìù –û–±—Ä–∞–±–æ—Ç–∫–∞ —è–∑—ã–∫–∞: {language}")

        # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ñ–∞–π–ª–æ–≤ –¥–ª—è —è–∑—ã–∫–∞
        merged_content = merge_files_for_language(
            args.base_path, language, args.category, args.files
        )

        if not merged_content:
            print(f"‚ùå {language}: –Ω–µ—Ç —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è")
            continue

        # –°–æ–∑–¥–∞–Ω–∏–µ –≤—ã—Ö–æ–¥–Ω–æ–≥–æ –ø—É—Ç–∏
        output_dir = os.path.join(args.base_path, language, 'story', args.category)
        os.makedirs(output_dir, exist_ok=True)
        output_path = os.path.join(output_dir, f"{args.output}.json")

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–∞–π–ª–∞
        if save_merged_file(output_path, merged_content, not args.compact):
            file_size = os.path.getsize(output_path)
            print(f"‚úÖ {language}: —Å–æ–∑–¥–∞–Ω {args.output}.json ({file_size} –±–∞–π—Ç)")
            success_count += 1
        else:
            print(f"‚ùå {language}: –æ—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ñ–∞–π–ª–∞")

    print(f"\nüéâ –ì–æ—Ç–æ–≤–æ! –£—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω–æ: {success_count}/{total_count} —Ñ–∞–π–ª–æ–≤")

    return 0

if __name__ == '__main__':
    exit(main())